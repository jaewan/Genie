{
  "baseline": "native_pytorch_smoke",
  "model_id": "gpt2",
  "prompt_tokens": 72,
  "new_tokens": 50,
  "batch_size": 1,
  "runs": [
    {
      "total_ms": 888.5670825839043,
      "per_token_ms": 17.771341651678085,
      "tokens_generated": 50,
      "throughput_tokens_per_s": 56.27037168043942,
      "host_to_device_mb": 0.00054931640625,
      "device_to_host_mb": 0.0009307861328125,
      "gpu_util_pct": null,
      "mem_util_pct": null,
      "mem_used_mb": null,
      "generated_text": null,
      "run_id": 1
    }
  ],
  "aggregates": {
    "total_ms": {
      "mean": 888.5670825839043,
      "median": 888.5670825839043,
      "p95": 888.5670825839043,
      "min": 888.5670825839043,
      "max": 888.5670825839043
    },
    "per_token_ms": {
      "mean": 17.771341651678085,
      "median": 17.771341651678085,
      "p95": 17.771341651678085,
      "min": 17.771341651678085,
      "max": 17.771341651678085
    },
    "throughput_tokens_per_s": {
      "mean": 56.27037168043942,
      "median": 56.27037168043942,
      "p95": 56.27037168043942,
      "min": 56.27037168043942,
      "max": 56.27037168043942
    }
  },
  "device": "cpu",
  "dtype": "float32",
  "seed": 42,
  "library_versions": {
    "torch": "2.9.0+cu128",
    "transformers": "4.57.1"
  },
  "meta": {
    "prompt_file": "Evaluation/exp2_1_llm_decode/configs/prompt.txt",
    "prompt_text": null,
    "sample_gpu": true
  }
}
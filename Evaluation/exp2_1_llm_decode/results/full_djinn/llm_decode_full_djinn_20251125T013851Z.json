{
  "baseline": "full_djinn",
  "model_id": "gpt2",
  "prompt_tokens": 32,
  "new_tokens": 10,
  "batch_size": 1,
  "runs": [
    {
      "total_ms": 157.568889670074,
      "per_token_ms": 15.756888967007399,
      "tokens_generated": 10,
      "throughput_tokens_per_s": 63.464304539674835,
      "host_to_device_mb": 0.0006256103515625,
      "device_to_host_mb": 7.860324859619141,
      "gpu_util_pct": null,
      "mem_util_pct": null,
      "mem_used_mb": null,
      "generated_text": "The",
      "run_id": 1
    },
    {
      "total_ms": 162.95445710420609,
      "per_token_ms": 16.29544571042061,
      "tokens_generated": 10,
      "throughput_tokens_per_s": 61.36683940841951,
      "host_to_device_mb": 0.0006256103515625,
      "device_to_host_mb": 7.860324859619141,
      "gpu_util_pct": null,
      "mem_util_pct": null,
      "mem_used_mb": null,
      "generated_text": "The",
      "run_id": 2
    },
    {
      "total_ms": 164.18543085455894,
      "per_token_ms": 16.418543085455894,
      "tokens_generated": 10,
      "throughput_tokens_per_s": 60.906743965963344,
      "host_to_device_mb": 0.0006256103515625,
      "device_to_host_mb": 7.860324859619141,
      "gpu_util_pct": null,
      "mem_util_pct": null,
      "mem_used_mb": null,
      "generated_text": "The",
      "run_id": 3
    }
  ],
  "aggregates": {
    "total_ms": {
      "mean": 161.56959254294634,
      "median": 162.95445710420609,
      "p95": 164.06233347952366,
      "min": 157.568889670074,
      "max": 164.18543085455894
    },
    "per_token_ms": {
      "mean": 16.156959254294634,
      "median": 16.29544571042061,
      "p95": 16.406233347952366,
      "min": 15.756888967007399,
      "max": 16.418543085455894
    },
    "throughput_tokens_per_s": {
      "mean": 61.91262930468589,
      "median": 61.36683940841951,
      "p95": 63.254558026549304,
      "min": 60.906743965963344,
      "max": 63.464304539674835
    }
  },
  "device": "Djinn remote (localhost:5556)",
  "dtype": "float16",
  "backend": "djinn",
  "djinn_server": "localhost:5556",
  "seed": 42,
  "library_versions": {
    "torch": "2.9.0+cu128",
    "transformers": "4.57.1"
  },
  "meta": {
    "prompt_file": null,
    "prompt_text": null,
    "sample_gpu": false
  }
}
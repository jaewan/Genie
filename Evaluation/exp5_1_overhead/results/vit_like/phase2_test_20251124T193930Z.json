{
  "config": "Evaluation/exp5_1_overhead/configs/overhead_smoke.yaml",
  "experiment": {
    "device": "cuda:0",
    "dtype": "float16",
    "runs": 3,
    "warmup_runs": 1,
    "tag": "smoke",
    "result_dir": "Evaluation/exp5_1_overhead/results",
    "djinn_server_address": "localhost:5556",
    "reference_baseline": "native_pytorch",
    "blind_baseline": "semantic_blind",
    "target_baseline": "full_djinn"
  },
  "workload": {
    "workload": "vit_like",
    "category": "vision",
    "timestamp": "2025-11-24T19:39:30.270443+00:00",
    "results": [
      {
        "baseline": "native_pytorch",
        "runner_type": "local_synthetic",
        "runs": [
          {
            "run_id": 1,
            "latency_ms": 8.113153278827667,
            "input_mb": 4.59375,
            "output_mb": 0.030517578125,
            "total_data_mb": 4.624267578125,
            "units_processed": 16.0,
            "throughput_units_per_s": 1972.1062144547532
          },
          {
            "run_id": 2,
            "latency_ms": 8.048690855503082,
            "input_mb": 4.59375,
            "output_mb": 0.030517578125,
            "total_data_mb": 4.624267578125,
            "units_processed": 16.0,
            "throughput_units_per_s": 1987.9009254107975
          },
          {
            "run_id": 3,
            "latency_ms": 8.049748837947845,
            "input_mb": 4.59375,
            "output_mb": 0.030517578125,
            "total_data_mb": 4.624267578125,
            "units_processed": 16.0,
            "throughput_units_per_s": 1987.6396546154779
          }
        ],
        "aggregates": {
          "latency_ms": {
            "mean": 8.070530990759531,
            "median": 8.049748837947845,
            "p95": 8.04964303970337,
            "min": 8.048690855503082,
            "max": 8.113153278827667
          },
          "throughput_units_per_s": {
            "mean": 1982.5489314936763,
            "median": 1987.6396546154779,
            "p95": 1987.6657816950099,
            "min": 1972.1062144547532,
            "max": 1987.9009254107975
          },
          "total_data_mb": {
            "mean": 4.624267578125,
            "median": 4.624267578125,
            "p95": 4.624267578125,
            "min": 4.624267578125,
            "max": 4.624267578125
          }
        },
        "metadata": {
          "unit_name": "images",
          "device": "cuda:0",
          "dtype": "float16",
          "spec": {
            "batch_size": 16,
            "in_channels": 3,
            "image_size": 224,
            "channels": [
              64,
              128,
              256
            ],
            "num_classes": 1000,
            "unit_name": "images"
          },
          "baseline": "native_pytorch",
          "runner_type": "local_synthetic"
        },
        "derived": {}
      },
      {
        "baseline": "semantic_blind",
        "runner_type": "scaling",
        "runs": [
          {
            "run_id": 1,
            "latency_ms": 40.565766394138336,
            "input_mb": 183.75,
            "output_mb": 1.220703125,
            "total_data_mb": 184.970703125,
            "units_processed": 16.0,
            "throughput_units_per_s": 394.4212428909506
          },
          {
            "run_id": 2,
            "latency_ms": 40.24345427751541,
            "input_mb": 183.75,
            "output_mb": 1.220703125,
            "total_data_mb": 184.970703125,
            "units_processed": 16.0,
            "throughput_units_per_s": 397.5801850821595
          },
          {
            "run_id": 3,
            "latency_ms": 40.24874418973923,
            "input_mb": 183.75,
            "output_mb": 1.220703125,
            "total_data_mb": 184.970703125,
            "units_processed": 16.0,
            "throughput_units_per_s": 397.5279309230956
          }
        ],
        "aggregates": {
          "latency_ms": {
            "mean": 40.35265495379766,
            "median": 40.24874418973923,
            "p95": 40.248215198516846,
            "min": 40.24345427751541,
            "max": 40.565766394138336
          },
          "throughput_units_per_s": {
            "mean": 396.50978629873526,
            "median": 397.5279309230956,
            "p95": 397.53315633900195,
            "min": 394.4212428909506,
            "max": 397.5801850821595
          },
          "total_data_mb": {
            "mean": 184.970703125,
            "median": 184.970703125,
            "p95": 184.970703125,
            "min": 184.970703125,
            "max": 184.970703125
          }
        },
        "metadata": {
          "baseline": "semantic_blind",
          "runner_type": "scaling",
          "reference": "native_pytorch",
          "notes": "Placeholder for Djinn semantics disabled (high latency + bandwidth). NOTE: Synthetic workloads cannot execute remotely - use overhead_hf_smoke.yaml for real remote execution with HuggingFace models."
        },
        "derived": {
          "latency_overhead_pct_vs_native_pytorch": 400.0000000000001
        }
      },
      {
        "baseline": "full_djinn",
        "runner_type": "scaling",
        "runs": [
          {
            "run_id": 1,
            "latency_ms": 9.51881094276905,
            "input_mb": 0.091875,
            "output_mb": 0.0006103515625,
            "total_data_mb": 0.0924853515625,
            "units_processed": 16.0,
            "throughput_units_per_s": 1878.1963947188124
          },
          {
            "run_id": 2,
            "latency_ms": 9.451125398278236,
            "input_mb": 0.091875,
            "output_mb": 0.0006103515625,
            "total_data_mb": 0.0924853515625,
            "units_processed": 16.0,
            "throughput_units_per_s": 1893.2389765817118
          },
          {
            "run_id": 3,
            "latency_ms": 9.452236279845238,
            "input_mb": 0.091875,
            "output_mb": 0.0006103515625,
            "total_data_mb": 0.0924853515625,
            "units_processed": 16.0,
            "throughput_units_per_s": 1892.990147252836
          }
        ],
        "aggregates": {
          "latency_ms": {
            "mean": 9.474057540297508,
            "median": 9.452236279845238,
            "p95": 9.452125191688538,
            "min": 9.451125398278236,
            "max": 9.51881094276905
          },
          "throughput_units_per_s": {
            "mean": 1888.1418395177868,
            "median": 1892.990147252836,
            "p95": 1893.0150301857236,
            "min": 1878.1963947188124,
            "max": 1893.2389765817118
          },
          "total_data_mb": {
            "mean": 0.0924853515625,
            "median": 0.0924853515625,
            "p95": 0.09248535156250001,
            "min": 0.0924853515625,
            "max": 0.0924853515625
          }
        },
        "metadata": {
          "baseline": "full_djinn",
          "runner_type": "scaling",
          "reference": "native_pytorch",
          "notes": "Placeholder for Djinn full semantics (low data, slight framework overhead). NOTE: Synthetic workloads cannot execute remotely - use overhead_hf_smoke.yaml for real remote execution with HuggingFace models."
        },
        "derived": {
          "latency_overhead_pct_vs_native_pytorch": 17.39075844135862,
          "speedup_vs_semantic_blind": 4.259279066245832,
          "data_savings_pct_vs_semantic_blind": 99.95,
          "semantic_efficiency_ratio": 5.747305405743512
        }
      }
    ]
  },
  "generated_at": "20251124T193930Z"
}
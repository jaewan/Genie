{
  "config": "Evaluation/exp5_1_overhead/configs/overhead_hf_smoke.yaml",
  "experiment": {
    "device": "cuda:0",
    "dtype": "float16",
    "runs": 2,
    "warmup_runs": 1,
    "tag": "hf_smoke",
    "result_dir": "Evaluation/exp5_1_overhead/results",
    "reference_baseline": "native_pytorch",
    "blind_baseline": "semantic_blind",
    "target_baseline": "full_djinn"
  },
  "workload": {
    "workload": "hf_tiny_gpt2",
    "category": "sequential",
    "timestamp": "2025-11-23T17:35:22.380084+00:00",
    "results": [
      {
        "baseline": "native_pytorch",
        "runner_type": "local_synthetic",
        "runs": [
          {
            "run_id": 1,
            "latency_ms": 135.6478724628687,
            "input_mb": 0.00048828125,
            "output_mb": 0.000732421875,
            "total_data_mb": 0.001220703125,
            "units_processed": 32.0,
            "throughput_units_per_s": 235.9049163027563
          },
          {
            "run_id": 2,
            "latency_ms": 135.35955920815468,
            "input_mb": 0.00048828125,
            "output_mb": 0.000732421875,
            "total_data_mb": 0.001220703125,
            "units_processed": 32.0,
            "throughput_units_per_s": 236.40738923204304
          }
        ],
        "aggregates": {
          "latency_ms": {
            "mean": 135.50371583551168,
            "median": 135.50371583551168,
            "p95": 135.37397487089038,
            "min": 135.35955920815468,
            "max": 135.6478724628687
          },
          "throughput_units_per_s": {
            "mean": 236.15615276739967,
            "median": 236.15615276739967,
            "p95": 236.38226558557872,
            "min": 235.9049163027563,
            "max": 236.40738923204304
          },
          "total_data_mb": {
            "mean": 0.001220703125,
            "median": 0.001220703125,
            "p95": 0.001220703125,
            "min": 0.001220703125,
            "max": 0.001220703125
          }
        },
        "metadata": {
          "unit_name": "tokens",
          "device": "cuda:0",
          "dtype": "float16",
          "spec": {
            "model_id": "sshleifer/tiny-gpt2",
            "prompt_text": "Djinn keeps KV caches remote while preserving semantic intent.",
            "prompt_length": 64,
            "new_tokens": 32,
            "batch_size": 1,
            "unit_name": "tokens",
            "generation": {
              "do_sample": false,
              "temperature": 0.0,
              "top_p": 1.0
            }
          },
          "baseline": "native_pytorch",
          "runner_type": "local_synthetic"
        },
        "derived": {}
      },
      {
        "baseline": "semantic_blind",
        "runner_type": "scaling",
        "runs": [
          {
            "run_id": 1,
            "latency_ms": 678.2393623143435,
            "input_mb": 0.0244140625,
            "output_mb": 0.03662109375,
            "total_data_mb": 0.06103515625,
            "units_processed": 32.0,
            "throughput_units_per_s": 47.18098326055126
          },
          {
            "run_id": 2,
            "latency_ms": 676.7977960407734,
            "input_mb": 0.0244140625,
            "output_mb": 0.03662109375,
            "total_data_mb": 0.06103515625,
            "units_processed": 32.0,
            "throughput_units_per_s": 47.281477846408606
          }
        ],
        "aggregates": {
          "latency_ms": {
            "mean": 677.5185791775584,
            "median": 677.5185791775584,
            "p95": 676.8698743544519,
            "min": 676.7977960407734,
            "max": 678.2393623143435
          },
          "throughput_units_per_s": {
            "mean": 47.23123055347993,
            "median": 47.23123055347993,
            "p95": 47.276453117115736,
            "min": 47.18098326055126,
            "max": 47.281477846408606
          },
          "total_data_mb": {
            "mean": 0.06103515625,
            "median": 0.06103515625,
            "p95": 0.06103515625,
            "min": 0.06103515625,
            "max": 0.06103515625
          }
        },
        "metadata": {
          "baseline": "semantic_blind",
          "runner_type": "scaling",
          "reference": "native_pytorch",
          "notes": "Placeholder for semantics disabled remote execution."
        },
        "derived": {
          "latency_overhead_pct_vs_native_pytorch": 400.0
        }
      },
      {
        "baseline": "full_djinn",
        "runner_type": "scaling",
        "runs": [
          {
            "run_id": 1,
            "latency_ms": 151.21265970915556,
            "input_mb": 9.765625e-06,
            "output_mb": 1.46484375e-05,
            "total_data_mb": 2.44140625e-05,
            "units_processed": 32.0,
            "throughput_units_per_s": 214.45901482068754
          },
          {
            "run_id": 2,
            "latency_ms": 150.89551512897015,
            "input_mb": 9.765625e-06,
            "output_mb": 1.46484375e-05,
            "total_data_mb": 2.44140625e-05,
            "units_processed": 32.0,
            "throughput_units_per_s": 214.9158083927664
          }
        ],
        "aggregates": {
          "latency_ms": {
            "mean": 151.05408741906285,
            "median": 151.05408741906285,
            "p95": 150.91137235797942,
            "min": 150.89551512897015,
            "max": 151.21265970915556
          },
          "throughput_units_per_s": {
            "mean": 214.68741160672698,
            "median": 214.68741160672698,
            "p95": 214.89296871416246,
            "min": 214.45901482068754,
            "max": 214.9158083927664
          },
          "total_data_mb": {
            "mean": 2.44140625e-05,
            "median": 2.44140625e-05,
            "p95": 2.44140625e-05,
            "min": 2.44140625e-05,
            "max": 2.44140625e-05
          }
        },
        "metadata": {
          "baseline": "full_djinn",
          "runner_type": "scaling",
          "reference": "native_pytorch",
          "notes": "Placeholder for Djinn full semantics (low data, modest overhead)."
        },
        "derived": {
          "latency_overhead_pct_vs_native_pytorch": 11.475974284297719,
          "speedup_vs_semantic_blind": 4.485271406777281,
          "data_savings_pct_vs_semantic_blind": 99.96000000000001,
          "semantic_efficiency_ratio": 8.710371557452225
        }
      }
    ]
  },
  "generated_at": "20251123T173522Z"
}
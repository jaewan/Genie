{
  "config": "Evaluation/exp5_1_overhead/configs/overhead_hf_smoke.yaml",
  "experiment": {
    "device": "cuda:0",
    "dtype": "float16",
    "runs": 2,
    "warmup_runs": 1,
    "tag": "hf_smoke",
    "result_dir": "Evaluation/exp5_1_overhead/results",
    "reference_baseline": "native_pytorch",
    "blind_baseline": "semantic_blind",
    "target_baseline": "full_djinn"
  },
  "workload": {
    "workload": "hf_tiny_gpt2",
    "category": "sequential",
    "timestamp": "2025-11-24T19:40:51.285982+00:00",
    "results": [
      {
        "baseline": "native_pytorch",
        "runner_type": "local_synthetic",
        "runs": [
          {
            "run_id": 1,
            "latency_ms": 147.9793442413211,
            "input_mb": 0.00048828125,
            "output_mb": 0.000732421875,
            "total_data_mb": 0.001220703125,
            "units_processed": 32.0,
            "throughput_units_per_s": 216.24639684721933
          },
          {
            "run_id": 2,
            "latency_ms": 151.55525784939528,
            "input_mb": 0.00048828125,
            "output_mb": 0.000732421875,
            "total_data_mb": 0.001220703125,
            "units_processed": 32.0,
            "throughput_units_per_s": 211.144109772815
          }
        ],
        "aggregates": {
          "latency_ms": {
            "mean": 149.76730104535818,
            "median": 149.76730104535818,
            "p95": 151.37646216899157,
            "min": 147.9793442413211,
            "max": 151.55525784939528
          },
          "throughput_units_per_s": {
            "mean": 213.69525331001716,
            "median": 213.69525331001716,
            "p95": 211.39922412653522,
            "min": 211.144109772815,
            "max": 216.24639684721933
          },
          "total_data_mb": {
            "mean": 0.001220703125,
            "median": 0.001220703125,
            "p95": 0.001220703125,
            "min": 0.001220703125,
            "max": 0.001220703125
          }
        },
        "metadata": {
          "unit_name": "tokens",
          "device": "cuda:0",
          "dtype": "float16",
          "spec": {
            "model_id": "sshleifer/tiny-gpt2",
            "prompt_text": "Djinn keeps KV caches remote while preserving semantic intent.",
            "prompt_length": 64,
            "new_tokens": 32,
            "batch_size": 1,
            "unit_name": "tokens",
            "generation": {
              "do_sample": false,
              "temperature": 0.0,
              "top_p": 1.0
            }
          },
          "baseline": "native_pytorch",
          "runner_type": "local_synthetic"
        },
        "derived": {}
      },
      {
        "baseline": "semantic_blind",
        "runner_type": "remote_djinn",
        "runs": [
          {
            "run_id": 1,
            "latency_ms": 63.12241870909929,
            "input_mb": 0.0009765625,
            "output_mb": 12.269775390625,
            "total_data_mb": 12.270751953125,
            "units_processed": 50257.0,
            "throughput_units_per_s": 796183.0523575183
          },
          {
            "run_id": 2,
            "latency_ms": 47.789440490305424,
            "input_mb": 0.0009765625,
            "output_mb": 12.269775390625,
            "total_data_mb": 12.270751953125,
            "units_processed": 50257.0,
            "throughput_units_per_s": 1051633.9903622672
          }
        ],
        "aggregates": {
          "latency_ms": {
            "mean": 55.45592959970236,
            "median": 55.45592959970236,
            "p95": 48.55608940124512,
            "min": 47.789440490305424,
            "max": 63.12241870909929
          },
          "throughput_units_per_s": {
            "mean": 923908.5213598928,
            "median": 923908.5213598928,
            "p95": 1038861.4434620298,
            "min": 796183.0523575183,
            "max": 1051633.9903622672
          },
          "total_data_mb": {
            "mean": 12.270751953125,
            "median": 12.270751953125,
            "p95": 12.270751953125,
            "min": 12.270751953125,
            "max": 12.270751953125
          }
        },
        "metadata": {
          "unit_name": "tokens",
          "device": "cpu",
          "dtype": "float32",
          "spec": {
            "model_id": "sshleifer/tiny-gpt2",
            "prompt_text": "Djinn keeps KV caches remote while preserving semantic intent.",
            "prompt_length": 64,
            "new_tokens": 32,
            "batch_size": 1,
            "unit_name": "tokens",
            "generation": {
              "do_sample": false,
              "temperature": 0.0,
              "top_p": 1.0
            }
          },
          "baseline": "semantic_blind",
          "runner_type": "remote_djinn",
          "semantic_aware": false
        },
        "derived": {
          "latency_overhead_pct_vs_native_pytorch": -62.97193765753507
        }
      },
      {
        "baseline": "full_djinn",
        "runner_type": "remote_djinn",
        "runs": [
          {
            "run_id": 1,
            "latency_ms": 67.375254817307,
            "input_mb": 0.0009765625,
            "output_mb": 12.269775390625,
            "total_data_mb": 12.270751953125,
            "units_processed": 50257.0,
            "throughput_units_per_s": 745926.6779216729
          },
          {
            "run_id": 2,
            "latency_ms": 54.23444602638483,
            "input_mb": 0.0009765625,
            "output_mb": 12.269775390625,
            "total_data_mb": 12.270751953125,
            "units_processed": 50257.0,
            "throughput_units_per_s": 926661.9958752815
          }
        ],
        "aggregates": {
          "latency_ms": {
            "mean": 60.80485042184591,
            "median": 60.80485042184591,
            "p95": 54.89148646593094,
            "min": 54.23444602638483,
            "max": 67.375254817307
          },
          "throughput_units_per_s": {
            "mean": 836294.3368984773,
            "median": 836294.3368984773,
            "p95": 917625.2299776011,
            "min": 745926.6779216729,
            "max": 926661.9958752815
          },
          "total_data_mb": {
            "mean": 12.270751953125,
            "median": 12.270751953125,
            "p95": 12.270751953125,
            "min": 12.270751953125,
            "max": 12.270751953125
          }
        },
        "metadata": {
          "unit_name": "tokens",
          "device": "cpu",
          "dtype": "float32",
          "spec": {
            "model_id": "sshleifer/tiny-gpt2",
            "prompt_text": "Djinn keeps KV caches remote while preserving semantic intent.",
            "prompt_length": 64,
            "new_tokens": 32,
            "batch_size": 1,
            "unit_name": "tokens",
            "generation": {
              "do_sample": false,
              "temperature": 0.0,
              "top_p": 1.0
            }
          },
          "baseline": "full_djinn",
          "runner_type": "remote_djinn",
          "semantic_aware": true
        },
        "derived": {
          "latency_overhead_pct_vs_native_pytorch": -59.400449899654205,
          "speedup_vs_semantic_blind": 0.9120313464298598,
          "data_savings_pct_vs_semantic_blind": 0.0,
          "semantic_efficiency_ratio": -0.0
        }
      }
    ]
  },
  "generated_at": "20251124T194051Z"
}
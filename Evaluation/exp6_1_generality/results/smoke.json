{
  "config": "Evaluation/exp6_1_generality/configs/generality_smoke.yaml",
  "generated_at": "20251123T185010Z",
  "experiment": {
    "device": "cuda:0",
    "dtype": "float16",
    "runs": 2,
    "warmup_runs": 1,
    "tag": "smoke",
    "djinn_server_address": "localhost:5556",
    "reference_baseline": "native_pytorch",
    "blind_baseline": "semantic_blind",
    "target_baseline": "full_djinn",
    "result_file": "Evaluation/exp6_1_generality/results/smoke.json"
  },
  "groups": [
    {
      "group": "sequential",
      "description": "LLM decode / streaming ASR",
      "workloads": [
        {
          "workload": "seq_llama_like",
          "category": "sequential",
          "timestamp": "2025-11-23T18:50:09.890152+00:00",
          "results": [
            {
              "baseline": "native_pytorch",
              "runner_type": "local_synthetic",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 18.313267268240452,
                  "input_mb": 2.5,
                  "output_mb": 2.5,
                  "total_data_mb": 5.0,
                  "units_processed": 640.0,
                  "throughput_units_per_s": 34947.34121583601
                },
                {
                  "run_id": 2,
                  "latency_ms": 21.829203702509403,
                  "input_mb": 2.5,
                  "output_mb": 2.5,
                  "total_data_mb": 5.0,
                  "units_processed": 640.0,
                  "throughput_units_per_s": 29318.522504163906
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 20.071235485374928,
                  "median": 20.071235485374928,
                  "p95": 21.653406880795956,
                  "min": 18.313267268240452,
                  "max": 21.829203702509403
                },
                "throughput_units_per_s": {
                  "mean": 32132.931859999957,
                  "median": 32132.931859999957,
                  "p95": 29599.963439747513,
                  "min": 29318.522504163906,
                  "max": 34947.34121583601
                },
                "total_data_mb": {
                  "mean": 5.0,
                  "median": 5.0,
                  "p95": 5.0,
                  "min": 5.0,
                  "max": 5.0
                }
              },
              "metadata": {
                "unit_name": "tokens",
                "device": "cuda:0",
                "dtype": "float16",
                "spec": {
                  "batch_size": 1,
                  "sequence_length": 640,
                  "hidden_size": 2048,
                  "num_layers": 16,
                  "num_heads": 16,
                  "ff_size": 8192,
                  "unit_name": "tokens"
                },
                "baseline": "native_pytorch",
                "runner_type": "local_synthetic"
              },
              "derived": {}
            },
            {
              "baseline": "semantic_blind",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 82.40970270708203,
                  "input_mb": 87.5,
                  "output_mb": 87.5,
                  "total_data_mb": 175.0,
                  "units_processed": 640.0,
                  "throughput_units_per_s": 7766.075825741335
                },
                {
                  "run_id": 2,
                  "latency_ms": 98.23141666129231,
                  "input_mb": 87.5,
                  "output_mb": 87.5,
                  "total_data_mb": 175.0,
                  "units_processed": 640.0,
                  "throughput_units_per_s": 6515.2272231475345
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 90.32055968418717,
                  "median": 90.32055968418717,
                  "p95": 97.4403309635818,
                  "min": 82.40970270708203,
                  "max": 98.23141666129231
                },
                "throughput_units_per_s": {
                  "mean": 7140.6515244444345,
                  "median": 7140.6515244444345,
                  "p95": 6577.769653277224,
                  "min": 6515.2272231475345,
                  "max": 7766.075825741335
                },
                "total_data_mb": {
                  "mean": 175.0,
                  "median": 175.0,
                  "p95": 175.0,
                  "min": 175.0,
                  "max": 175.0
                }
              },
              "metadata": {
                "baseline": "semantic_blind",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for semantics disabled"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 350.0
              }
            },
            {
              "baseline": "full_djinn",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 20.278328649699688,
                  "input_mb": 0.075,
                  "output_mb": 0.075,
                  "total_data_mb": 0.15,
                  "units_processed": 640.0,
                  "throughput_units_per_s": 32358.649273922227
                },
                {
                  "run_id": 2,
                  "latency_ms": 24.075539998710155,
                  "input_mb": 0.075,
                  "output_mb": 0.075,
                  "total_data_mb": 0.15,
                  "units_processed": 640.0,
                  "throughput_units_per_s": 27146.78009644806
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 22.17693432420492,
                  "median": 22.17693432420492,
                  "p95": 23.885679431259632,
                  "min": 20.278328649699688,
                  "max": 24.075539998710155
                },
                "throughput_units_per_s": {
                  "mean": 29752.714685185143,
                  "median": 29752.714685185143,
                  "p95": 27407.37355532177,
                  "min": 27146.78009644806,
                  "max": 32358.649273922227
                },
                "total_data_mb": {
                  "mean": 0.15,
                  "median": 0.15,
                  "p95": 0.15,
                  "min": 0.15,
                  "max": 0.15
                }
              },
              "metadata": {
                "baseline": "full_djinn",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for Djinn with semantics"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 10.491127167355142,
                "speedup_vs_semantic_blind": 4.072725218183434,
                "data_savings_pct_vs_semantic_blind": 99.91428571428571,
                "semantic_efficiency_ratio": 9.523694081717487
              }
            }
          ]
        },
        {
          "workload": "seq_audio_like",
          "category": "sequential",
          "timestamp": "2025-11-23T18:50:10.054358+00:00",
          "results": [
            {
              "baseline": "native_pytorch",
              "runner_type": "local_synthetic",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 7.838595658540726,
                  "input_mb": 4.0,
                  "output_mb": 4.0,
                  "total_data_mb": 8.0,
                  "units_processed": 2048.0,
                  "throughput_units_per_s": 261271.29006438208
                },
                {
                  "run_id": 2,
                  "latency_ms": 7.8332070261240005,
                  "input_mb": 4.0,
                  "output_mb": 4.0,
                  "total_data_mb": 8.0,
                  "units_processed": 2048.0,
                  "throughput_units_per_s": 261451.02423181888
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 7.835901342332363,
                  "median": 7.835901342332363,
                  "p95": 7.833476457744837,
                  "min": 7.8332070261240005,
                  "max": 7.838595658540726
                },
                "throughput_units_per_s": {
                  "mean": 261361.1571481005,
                  "median": 261361.1571481005,
                  "p95": 261442.03752344704,
                  "min": 261271.29006438208,
                  "max": 261451.02423181888
                },
                "total_data_mb": {
                  "mean": 8.0,
                  "median": 8.0,
                  "p95": 8.0,
                  "min": 8.0,
                  "max": 8.0
                }
              },
              "metadata": {
                "unit_name": "frames",
                "device": "cuda:0",
                "dtype": "float16",
                "spec": {
                  "batch_size": 2,
                  "sequence_length": 1024,
                  "hidden_size": 1024,
                  "num_layers": 8,
                  "num_heads": 8,
                  "ff_size": 4096,
                  "unit_name": "frames"
                },
                "baseline": "native_pytorch",
                "runner_type": "local_synthetic"
              },
              "derived": {}
            },
            {
              "baseline": "semantic_blind",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 35.273680463433266,
                  "input_mb": 140.0,
                  "output_mb": 140.0,
                  "total_data_mb": 280.0,
                  "units_processed": 2048.0,
                  "throughput_units_per_s": 58060.2866809738
                },
                {
                  "run_id": 2,
                  "latency_ms": 35.249431617558,
                  "input_mb": 140.0,
                  "output_mb": 140.0,
                  "total_data_mb": 280.0,
                  "units_processed": 2048.0,
                  "throughput_units_per_s": 58100.22760707086
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 35.261556040495634,
                  "median": 35.261556040495634,
                  "p95": 35.250644059851766,
                  "min": 35.249431617558,
                  "max": 35.273680463433266
                },
                "throughput_units_per_s": {
                  "mean": 58080.257144022326,
                  "median": 58080.257144022326,
                  "p95": 58098.23056076601,
                  "min": 58060.2866809738,
                  "max": 58100.22760707086
                },
                "total_data_mb": {
                  "mean": 280.0,
                  "median": 280.0,
                  "p95": 280.0,
                  "min": 280.0,
                  "max": 280.0
                }
              },
              "metadata": {
                "baseline": "semantic_blind",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for semantics disabled"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 350.0
              }
            },
            {
              "baseline": "full_djinn",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 8.965683311223984,
                  "input_mb": 0.12,
                  "output_mb": 0.12,
                  "total_data_mb": 0.24,
                  "units_processed": 2048.0,
                  "throughput_units_per_s": 241917.86117072412
                },
                {
                  "run_id": 2,
                  "latency_ms": 8.95986358821392,
                  "input_mb": 0.12,
                  "output_mb": 0.12,
                  "total_data_mb": 0.24,
                  "units_processed": 2048.0,
                  "throughput_units_per_s": 242084.28169612857
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 8.962773449718952,
                  "median": 8.962773449718952,
                  "p95": 8.960154574364424,
                  "min": 8.95986358821392,
                  "max": 8.965683311223984
                },
                "throughput_units_per_s": {
                  "mean": 242001.07143342635,
                  "median": 242001.07143342635,
                  "p95": 242075.96066985835,
                  "min": 241917.86117072412,
                  "max": 242084.28169612857
                },
                "total_data_mb": {
                  "mean": 0.24,
                  "median": 0.24,
                  "p95": 0.24,
                  "min": 0.24,
                  "max": 0.24
                }
              },
              "metadata": {
                "baseline": "full_djinn",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for Djinn with semantics"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 14.380886871288446,
                "speedup_vs_semantic_blind": 3.9342237353551917,
                "data_savings_pct_vs_semantic_blind": 99.91428571428571,
                "semantic_efficiency_ratio": 6.94771376817972
              }
            }
          ]
        }
      ]
    },
    {
      "group": "parallel",
      "description": "Vision inference / stateless batching",
      "workloads": [
        {
          "workload": "par_resnet_like",
          "category": "parallel",
          "timestamp": "2025-11-23T18:50:10.306037+00:00",
          "results": [
            {
              "baseline": "native_pytorch",
              "runner_type": "local_synthetic",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 18.144503235816956,
                  "input_mb": 9.1875,
                  "output_mb": 0.06103515625,
                  "total_data_mb": 9.24853515625,
                  "units_processed": 32.0,
                  "throughput_units_per_s": 1763.6195151836682
                },
                {
                  "run_id": 2,
                  "latency_ms": 18.18102039396763,
                  "input_mb": 9.1875,
                  "output_mb": 0.06103515625,
                  "total_data_mb": 9.24853515625,
                  "units_processed": 32.0,
                  "throughput_units_per_s": 1760.0772292526244
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 18.162761814892292,
                  "median": 18.162761814892292,
                  "p95": 18.179194536060095,
                  "min": 18.144503235816956,
                  "max": 18.18102039396763
                },
                "throughput_units_per_s": {
                  "mean": 1761.8483722181463,
                  "median": 1761.8483722181463,
                  "p95": 1760.2543435491766,
                  "min": 1760.0772292526244,
                  "max": 1763.6195151836682
                },
                "total_data_mb": {
                  "mean": 9.24853515625,
                  "median": 9.24853515625,
                  "p95": 9.24853515625,
                  "min": 9.24853515625,
                  "max": 9.24853515625
                }
              },
              "metadata": {
                "unit_name": "images",
                "device": "cuda:0",
                "dtype": "float16",
                "spec": {
                  "batch_size": 32,
                  "in_channels": 3,
                  "image_size": 224,
                  "channels": [
                    64,
                    128,
                    256,
                    256
                  ],
                  "num_classes": 1000,
                  "unit_name": "images"
                },
                "baseline": "native_pytorch",
                "runner_type": "local_synthetic"
              },
              "derived": {}
            },
            {
              "baseline": "semantic_blind",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 81.6502645611763,
                  "input_mb": 321.5625,
                  "output_mb": 2.13623046875,
                  "total_data_mb": 323.69873046875,
                  "units_processed": 32.0,
                  "throughput_units_per_s": 391.91544781859295
                },
                {
                  "run_id": 2,
                  "latency_ms": 81.81459177285433,
                  "input_mb": 321.5625,
                  "output_mb": 2.13623046875,
                  "total_data_mb": 323.69873046875,
                  "units_processed": 32.0,
                  "throughput_units_per_s": 391.12827316724986
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 81.73242816701531,
                  "median": 81.73242816701531,
                  "p95": 81.80637541227043,
                  "min": 81.6502645611763,
                  "max": 81.81459177285433
                },
                "throughput_units_per_s": {
                  "mean": 391.5218604929214,
                  "median": 391.5218604929214,
                  "p95": 391.167631899817,
                  "min": 391.12827316724986,
                  "max": 391.91544781859295
                },
                "total_data_mb": {
                  "mean": 323.69873046875,
                  "median": 323.69873046875,
                  "p95": 323.69873046875,
                  "min": 323.69873046875,
                  "max": 323.69873046875
                }
              },
              "metadata": {
                "baseline": "semantic_blind",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for semantics disabled"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 350.0
              }
            },
            {
              "baseline": "full_djinn",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 20.096063494682312,
                  "input_mb": 0.275625,
                  "output_mb": 0.0018310546875,
                  "total_data_mb": 0.2774560546875,
                  "units_processed": 32.0,
                  "throughput_units_per_s": 1632.9810325774704
                },
                {
                  "run_id": 2,
                  "latency_ms": 20.13550202548504,
                  "input_mb": 0.275625,
                  "output_mb": 0.0018310546875,
                  "total_data_mb": 0.2774560546875,
                  "units_processed": 32.0,
                  "throughput_units_per_s": 1629.7011381968744
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 20.115782760083675,
                  "median": 20.115782760083675,
                  "p95": 20.133530098944902,
                  "min": 20.096063494682312,
                  "max": 20.13550202548504
                },
                "throughput_units_per_s": {
                  "mean": 1631.3410853871724,
                  "median": 1631.3410853871724,
                  "p95": 1629.8651329159043,
                  "min": 1629.7011381968744,
                  "max": 1632.9810325774704
                },
                "total_data_mb": {
                  "mean": 0.2774560546875,
                  "median": 0.2774560546875,
                  "p95": 0.2774560546875,
                  "min": 0.2774560546875,
                  "max": 0.2774560546875
                }
              },
              "metadata": {
                "baseline": "full_djinn",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for Djinn with semantics"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 10.752885299580562,
                "speedup_vs_semantic_blind": 4.063099564248592,
                "data_savings_pct_vs_semantic_blind": 99.91428571428573,
                "semantic_efficiency_ratio": 9.291858225083372
              }
            }
          ]
        },
        {
          "workload": "par_vit_like",
          "category": "parallel",
          "timestamp": "2025-11-23T18:50:10.439892+00:00",
          "results": [
            {
              "baseline": "native_pytorch",
              "runner_type": "local_synthetic",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 40.744299069046974,
                  "input_mb": 13.5,
                  "output_mb": 0.030517578125,
                  "total_data_mb": 13.530517578125,
                  "units_processed": 16.0,
                  "throughput_units_per_s": 392.69297461433166
                },
                {
                  "run_id": 2,
                  "latency_ms": 40.81863071769476,
                  "input_mb": 13.5,
                  "output_mb": 0.030517578125,
                  "total_data_mb": 13.530517578125,
                  "units_processed": 16.0,
                  "throughput_units_per_s": 391.9778718364515
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 40.78146489337087,
                  "median": 40.78146489337087,
                  "p95": 40.81491413526237,
                  "min": 40.744299069046974,
                  "max": 40.81863071769476
                },
                "throughput_units_per_s": {
                  "mean": 392.3354232253916,
                  "median": 392.3354232253916,
                  "p95": 392.0136269753455,
                  "min": 391.9778718364515,
                  "max": 392.69297461433166
                },
                "total_data_mb": {
                  "mean": 13.530517578125,
                  "median": 13.530517578125,
                  "p95": 13.530517578125,
                  "min": 13.530517578125,
                  "max": 13.530517578125
                }
              },
              "metadata": {
                "unit_name": "images",
                "device": "cuda:0",
                "dtype": "float16",
                "spec": {
                  "batch_size": 16,
                  "in_channels": 3,
                  "image_size": 384,
                  "channels": [
                    96,
                    192,
                    384
                  ],
                  "num_classes": 1000,
                  "unit_name": "images"
                },
                "baseline": "native_pytorch",
                "runner_type": "local_synthetic"
              },
              "derived": {}
            },
            {
              "baseline": "semantic_blind",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 183.34934581071138,
                  "input_mb": 472.5,
                  "output_mb": 1.068115234375,
                  "total_data_mb": 473.568115234375,
                  "units_processed": 16.0,
                  "throughput_units_per_s": 87.26510546985148
                },
                {
                  "run_id": 2,
                  "latency_ms": 183.68383822962642,
                  "input_mb": 472.5,
                  "output_mb": 1.068115234375,
                  "total_data_mb": 473.568115234375,
                  "units_processed": 16.0,
                  "throughput_units_per_s": 87.10619374143367
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 183.5165920201689,
                  "median": 183.5165920201689,
                  "p95": 183.66711360868067,
                  "min": 183.34934581071138,
                  "max": 183.68383822962642
                },
                "throughput_units_per_s": {
                  "mean": 87.18564960564257,
                  "median": 87.18564960564257,
                  "p95": 87.11413932785457,
                  "min": 87.10619374143367,
                  "max": 87.26510546985148
                },
                "total_data_mb": {
                  "mean": 473.568115234375,
                  "median": 473.568115234375,
                  "p95": 473.568115234375,
                  "min": 473.568115234375,
                  "max": 473.568115234375
                }
              },
              "metadata": {
                "baseline": "semantic_blind",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for semantics disabled"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 350.0
              }
            },
            {
              "baseline": "full_djinn",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 44.50384299457073,
                  "input_mb": 0.40499999999999997,
                  "output_mb": 0.00091552734375,
                  "total_data_mb": 0.40591552734374997,
                  "units_processed": 16.0,
                  "throughput_units_per_s": 363.6046061243811
                },
                {
                  "run_id": 2,
                  "latency_ms": 44.58412117511034,
                  "input_mb": 0.40499999999999997,
                  "output_mb": 0.00091552734375,
                  "total_data_mb": 0.40591552734374997,
                  "units_processed": 16.0,
                  "throughput_units_per_s": 362.94247392264026
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 44.543982084840536,
                  "median": 44.543982084840536,
                  "p95": 44.58010726608336,
                  "min": 44.50384299457073,
                  "max": 44.58412117511034
                },
                "throughput_units_per_s": {
                  "mean": 363.2735400235107,
                  "median": 363.2735400235107,
                  "p95": 362.9755805327273,
                  "min": 362.94247392264026,
                  "max": 363.6046061243811
                },
                "total_data_mb": {
                  "mean": 0.40591552734374997,
                  "median": 0.40591552734374997,
                  "p95": 0.40591552734375,
                  "min": 0.40591552734374997,
                  "max": 0.40591552734374997
                }
              },
              "metadata": {
                "baseline": "full_djinn",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for Djinn with semantics"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 9.226047179294138,
                "speedup_vs_semantic_blind": 4.1198964131818006,
                "data_savings_pct_vs_semantic_blind": 99.91428571428573,
                "semantic_efficiency_ratio": 10.829587554952209
              }
            }
          ]
        }
      ]
    },
    {
      "group": "hybrid",
      "description": "Multimodal (e.g., CLIP)",
      "workloads": [
        {
          "workload": "hybrid_clip_like",
          "category": "hybrid",
          "timestamp": "2025-11-23T18:50:10.563596+00:00",
          "results": [
            {
              "baseline": "native_pytorch",
              "runner_type": "local_synthetic",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 28.076741844415665,
                  "input_mb": 2.296875,
                  "output_mb": 0.015625,
                  "total_data_mb": 2.3125,
                  "units_processed": 401408.0,
                  "throughput_units_per_s": 14296815.57156313
                },
                {
                  "run_id": 2,
                  "latency_ms": 29.990329407155514,
                  "input_mb": 2.296875,
                  "output_mb": 0.015625,
                  "total_data_mb": 2.3125,
                  "units_processed": 401408.0,
                  "throughput_units_per_s": 13384581.227848282
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 29.03353562578559,
                  "median": 29.03353562578559,
                  "p95": 29.89465002901852,
                  "min": 28.076741844415665,
                  "max": 29.990329407155514
                },
                "throughput_units_per_s": {
                  "mean": 13840698.399705706,
                  "median": 13840698.399705706,
                  "p95": 13430192.945034023,
                  "min": 13384581.227848282,
                  "max": 14296815.57156313
                },
                "total_data_mb": {
                  "mean": 2.3125,
                  "median": 2.3125,
                  "p95": 2.3125,
                  "min": 2.3125,
                  "max": 2.3125
                }
              },
              "metadata": {
                "unit_name": "image_tokens",
                "device": "cuda:0",
                "dtype": "float16",
                "spec": {
                  "batch_size": 8,
                  "in_channels": 3,
                  "image_size": 224,
                  "channels": [
                    64,
                    128
                  ],
                  "hidden_size": 512,
                  "num_layers": 4,
                  "num_heads": 8,
                  "ff_size": 2048,
                  "num_classes": 1024,
                  "unit_name": "image_tokens"
                },
                "baseline": "native_pytorch",
                "runner_type": "local_synthetic"
              },
              "derived": {}
            },
            {
              "baseline": "semantic_blind",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 126.34533829987049,
                  "input_mb": 80.390625,
                  "output_mb": 0.546875,
                  "total_data_mb": 80.9375,
                  "units_processed": 401408.0,
                  "throughput_units_per_s": 3177070.127014029
                },
                {
                  "run_id": 2,
                  "latency_ms": 134.9564823321998,
                  "input_mb": 80.390625,
                  "output_mb": 0.546875,
                  "total_data_mb": 80.9375,
                  "units_processed": 401408.0,
                  "throughput_units_per_s": 2974351.383966285
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 130.65091031603515,
                  "median": 130.65091031603515,
                  "p95": 134.52592513058335,
                  "min": 126.34533829987049,
                  "max": 134.9564823321998
                },
                "throughput_units_per_s": {
                  "mean": 3075710.755490157,
                  "median": 3075710.755490157,
                  "p95": 2984487.321118672,
                  "min": 2974351.383966285,
                  "max": 3177070.127014029
                },
                "total_data_mb": {
                  "mean": 80.9375,
                  "median": 80.9375,
                  "p95": 80.9375,
                  "min": 80.9375,
                  "max": 80.9375
                }
              },
              "metadata": {
                "baseline": "semantic_blind",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for semantics disabled"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 350.0
              }
            },
            {
              "baseline": "full_djinn",
              "runner_type": "scaling",
              "runs": [
                {
                  "run_id": 1,
                  "latency_ms": 30.82288119196892,
                  "input_mb": 0.06890625,
                  "output_mb": 0.00046875,
                  "total_data_mb": 0.069375,
                  "units_processed": 401408.0,
                  "throughput_units_per_s": 13237792.195891786
                },
                {
                  "run_id": 2,
                  "latency_ms": 32.889555759727955,
                  "input_mb": 0.06890625,
                  "output_mb": 0.00046875,
                  "total_data_mb": 0.069375,
                  "units_processed": 401408.0,
                  "throughput_units_per_s": 12393130.766526187
                }
              ],
              "aggregates": {
                "latency_ms": {
                  "mean": 31.856218475848436,
                  "median": 31.856218475848436,
                  "p95": 32.78622203134,
                  "min": 30.82288119196892,
                  "max": 32.889555759727955
                },
                "throughput_units_per_s": {
                  "mean": 12815461.481208988,
                  "median": 12815461.481208988,
                  "p95": 12435363.837994467,
                  "min": 12393130.766526187,
                  "max": 13237792.195891786
                },
                "total_data_mb": {
                  "mean": 0.069375,
                  "median": 0.069375,
                  "p95": 0.069375,
                  "min": 0.069375,
                  "max": 0.069375
                }
              },
              "metadata": {
                "baseline": "full_djinn",
                "runner_type": "scaling",
                "reference": "native_pytorch",
                "notes": "Placeholder for Djinn with semantics"
              },
              "derived": {
                "latency_overhead_pct_vs_native_pytorch": 9.722146439360735,
                "speedup_vs_semantic_blind": 4.101268655445944,
                "data_savings_pct_vs_semantic_blind": 99.91428571428573,
                "semantic_efficiency_ratio": 10.276978066260792
              }
            }
          ]
        }
      ]
    }
  ],
  "summaries": [
    {
      "group": "sequential",
      "num_workloads": 2,
      "metrics": {
        "speedup_vs_blind": {
          "mean": 4.003474476769313,
          "median": 4.003474476769313,
          "p95": 3.941148809496604,
          "min": 3.9342237353551917,
          "max": 4.072725218183434
        },
        "data_savings_pct_vs_blind": {
          "mean": 99.91428571428571,
          "median": 99.91428571428571,
          "p95": 99.91428571428571,
          "min": 99.91428571428571,
          "max": 99.91428571428571
        },
        "semantic_efficiency_ratio": {
          "mean": 8.235703924948604,
          "median": 8.235703924948604,
          "p95": 7.076512783856609,
          "min": 6.94771376817972,
          "max": 9.523694081717487
        }
      }
    },
    {
      "group": "parallel",
      "num_workloads": 2,
      "metrics": {
        "speedup_vs_blind": {
          "mean": 4.091497988715196,
          "median": 4.091497988715196,
          "p95": 4.117056570735141,
          "min": 4.063099564248592,
          "max": 4.1198964131818006
        },
        "data_savings_pct_vs_blind": {
          "mean": 99.91428571428573,
          "median": 99.91428571428573,
          "p95": 99.91428571428573,
          "min": 99.91428571428573,
          "max": 99.91428571428573
        },
        "semantic_efficiency_ratio": {
          "mean": 10.06072289001779,
          "median": 10.06072289001779,
          "p95": 10.752701088458766,
          "min": 9.291858225083372,
          "max": 10.829587554952209
        }
      }
    },
    {
      "group": "hybrid",
      "num_workloads": 1,
      "metrics": {
        "speedup_vs_blind": {
          "mean": 4.101268655445944,
          "median": 4.101268655445944,
          "p95": 4.101268655445944,
          "min": 4.101268655445944,
          "max": 4.101268655445944
        },
        "data_savings_pct_vs_blind": {
          "mean": 99.91428571428573,
          "median": 99.91428571428573,
          "p95": 99.91428571428573,
          "min": 99.91428571428573,
          "max": 99.91428571428573
        },
        "semantic_efficiency_ratio": {
          "mean": 10.276978066260792,
          "median": 10.276978066260792,
          "p95": 10.276978066260792,
          "min": 10.276978066260792,
          "max": 10.276978066260792
        }
      }
    }
  ]
}
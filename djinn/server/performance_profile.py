"""
Performance Profile: Versioned execution policy for models.

This is the core data structure for Djinn v2.0 architecture.
Profiles are generated offline by AnalysisPipeline and stored in ProfileRegistry.
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple
from enum import Enum
import time
import hashlib
import json


class ExecutionPhase(Enum):
    """Execution phase classification."""
    LLM_PREFILL = "llm_prefill"
    LLM_DECODE = "llm_decode"
    VISION_ENCODING = "vision_encoding"
    TRAINING = "training"
    UNKNOWN = "unknown"


class OptimizationDirective(Enum):
    """Optimization directives for execution."""
    ENABLE_FUSION = "enable_fusion"
    ENABLE_COMPILATION = "enable_compilation"
    ENABLE_PIPELINING = "enable_pipelining"
    RECOMPUTE_ACTIVATIONS = "recompute_activations"


@dataclass
class InputEnvelope:
    """
    Defines the input shapes this profile is valid for.
    
    Supports exact match or range-based matching.
    """
    # Input name -> (min_shape, max_shape) or exact shape
    shape_constraints: Dict[str, Tuple[Tuple[int, ...], Tuple[int, ...]]]
    dtype_constraints: Dict[str, str] = field(default_factory=dict)
    
    def matches(self, inputs: Dict[str, Tuple[int, ...]]) -> bool:
        """Check if inputs match this envelope."""
        for name, shape in inputs.items():
            if name not in self.shape_constraints:
                return False
            min_shape, max_shape = self.shape_constraints[name]
            # Check each dimension
            if len(shape) != len(min_shape):
                return False
            for s, min_s, max_s in zip(shape, min_shape, max_shape):
                if not (min_s <= s <= max_s):
                    return False
        return True


@dataclass
class ResourceBudget:
    """Memory allocation budgets for different data types."""
    activations_fraction: float = 0.4  # 40% for activations
    weights_fraction: float = 0.3      # 30% for weights
    kv_cache_fraction: float = 0.3     # 30% for KV cache
    
    def validate(self) -> bool:
        """Validate budgets sum to ~1.0."""
        total = self.activations_fraction + self.weights_fraction + self.kv_cache_fraction
        return abs(total - 1.0) < 0.01  # Allow 1% tolerance


@dataclass
class PerformanceProfile:
    """
    Versioned execution policy for a model workload pattern.
    
    This is the core artifact of Djinn v2.0 architecture.
    Generated by AnalysisPipeline, stored in ProfileRegistry.
    """
    # Identity
    profile_id: str  # Unique identifier (hash of fingerprint + input envelope)
    model_fingerprint: str  # Model this profile applies to
    version: int = 1  # Profile version (incremented on updates)
    
    # Input specification
    input_envelope: Optional[InputEnvelope] = None
    
    # Execution characteristics
    execution_phase: ExecutionPhase = ExecutionPhase.UNKNOWN
    resource_budget: Optional[ResourceBudget] = None
    
    # Optimization directives
    optimization_directives: List[OptimizationDirective] = field(default_factory=list)
    
    # Placement constraints
    placement_constraints: Dict[str, str] = field(default_factory=dict)
    
    # Metadata
    created_at: float = field(default_factory=time.time)
    updated_at: float = field(default_factory=time.time)
    
    # Telemetry (populated from runtime observations)
    observed_latency_ms: Optional[float] = None
    observed_memory_gb: Optional[float] = None
    observation_count: int = 0
    
    @staticmethod
    def generate_profile_id(model_fingerprint: str, input_shapes: Dict[str, Tuple[int, ...]]) -> str:
        """Generate deterministic profile ID from fingerprint + input shapes."""
        # Create stable representation of inputs
        input_repr = json.dumps(
            {k: list(v) for k, v in sorted(input_shapes.items())},
            sort_keys=True
        )
        combined = f"{model_fingerprint}:{input_repr}"
        # 128-bit identifier to avoid collision risk
        return hashlib.sha256(combined.encode()).hexdigest()[:32]
    
    def validate(self) -> Tuple[bool, List[str]]:
        """
        Validate profile consistency.
        
        Returns:
            (is_valid, list_of_errors)
        """
        errors = []
        
        # Check resource budget sums to 1.0
        if self.resource_budget and not self.resource_budget.validate():
            errors.append("Resource budget fractions don't sum to 1.0")
        
        # Check profile_id matches fingerprint
        if not self.profile_id:
            errors.append("profile_id is required")
        
        if not self.model_fingerprint:
            errors.append("model_fingerprint is required")
        
        return (len(errors) == 0, errors)
    
    def to_dict(self) -> Dict:
        """Serialize to dict for storage/transmission."""
        return {
            'profile_id': self.profile_id,
            'model_fingerprint': self.model_fingerprint,
            'version': self.version,
            'input_envelope': {
                'shape_constraints': {
                    k: [list(v[0]), list(v[1])] 
                    for k, v in (self.input_envelope.shape_constraints.items() if self.input_envelope else {})
                },
                'dtype_constraints': self.input_envelope.dtype_constraints if self.input_envelope else {}
            } if self.input_envelope else None,
            'execution_phase': self.execution_phase.value,
            'resource_budget': {
                'activations_fraction': self.resource_budget.activations_fraction,
                'weights_fraction': self.resource_budget.weights_fraction,
                'kv_cache_fraction': self.resource_budget.kv_cache_fraction,
            } if self.resource_budget else None,
            'optimization_directives': [d.value for d in self.optimization_directives],
            'placement_constraints': self.placement_constraints,
            'created_at': self.created_at,
            'updated_at': self.updated_at,
            'observed_latency_ms': self.observed_latency_ms,
            'observed_memory_gb': self.observed_memory_gb,
            'observation_count': self.observation_count,
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'PerformanceProfile':
        """Deserialize from dict."""
        input_envelope = None
        if data.get('input_envelope'):
            env_data = data['input_envelope']
            input_envelope = InputEnvelope(
                shape_constraints={
                    k: (tuple(v[0]), tuple(v[1]))
                    for k, v in env_data['shape_constraints'].items()
                },
                dtype_constraints=env_data.get('dtype_constraints', {})
            )
        
        resource_budget = None
        if data.get('resource_budget'):
            rb_data = data['resource_budget']
            resource_budget = ResourceBudget(
                activations_fraction=rb_data['activations_fraction'],
                weights_fraction=rb_data['weights_fraction'],
                kv_cache_fraction=rb_data['kv_cache_fraction'],
            )
        
        return cls(
            profile_id=data['profile_id'],
            model_fingerprint=data['model_fingerprint'],
            version=data.get('version', 1),
            input_envelope=input_envelope,
            execution_phase=ExecutionPhase(data.get('execution_phase', 'unknown')),
            resource_budget=resource_budget,
            optimization_directives=[
                OptimizationDirective(d) for d in data.get('optimization_directives', [])
            ],
            placement_constraints=data.get('placement_constraints', {}),
            created_at=data.get('created_at', time.time()),
            updated_at=data.get('updated_at', time.time()),
            observed_latency_ms=data.get('observed_latency_ms'),
            observed_memory_gb=data.get('observed_memory_gb'),
            observation_count=data.get('observation_count', 0),
        )


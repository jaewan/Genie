from __future__ import annotations

import logging
import os
from typing import Any, Dict, Optional

import torch

from .graph import GraphBuilder
from .errors import MaterializationError, UnsupportedOperationError

logger = logging.getLogger(__name__)


class SimpleExecutor:
	"""Simple local executor for Phase 1.
	
	Executes LazyTensor graphs eagerly on CPU for validation and testing.
	In later phases, this will be replaced with remote execution.
	"""

	def __init__(self):
		self.execution_count = 0
		self.operation_handlers = self._build_operation_handlers()

	def _build_operation_handlers(self) -> Dict[str, callable]:
		"""Build mapping of operations to handler functions."""
		return {
			# Arithmetic operations
			"aten::add": self._execute_add,
			"aten::sub": self._execute_sub,
			"aten::mul": self._execute_mul,
			"aten::div": self._execute_div,

			# No-op alias (used by lift)
			"aten::alias": self._execute_alias,
			
			# Linear algebra
			"aten::matmul": self._execute_matmul,
			# NOTE: Intentionally omit explicit handlers for mm/bmm to exercise unified fallback
			
			# Tensor creation
			"aten::randn": self._execute_randn,
			"aten::zeros": self._execute_zeros,
			"aten::ones": self._execute_ones,
			
			# Activations
			"aten::relu": self._execute_relu,
			"aten::sigmoid": self._execute_sigmoid,
			"aten::tanh": self._execute_tanh,
			
			# Convolution
			"aten::conv2d": self._execute_conv2d,
			
			# Reductions
			"aten::sum": self._execute_sum,
			"aten::mean": self._execute_mean,
			"aten::var": self._execute_var,
			"aten::std": self._execute_std,
			"aten::argmax": self._execute_argmax,
			"aten::argmin": self._execute_argmin,
			"aten::softmax": self._execute_softmax,
		}

	def execute_subgraph(self, target_lazy_tensor) -> torch.Tensor:  # noqa: ANN001
		"""Execute computation graph up to target tensor."""
		self.execution_count += 1

		# Check if this is a remote execution (Week 2 enhancement)
		if hasattr(target_lazy_tensor, 'device') and target_lazy_tensor.device:
			if isinstance(target_lazy_tensor.device, torch.device):
				is_remote = target_lazy_tensor.device.type == "remote_accelerator"
			elif isinstance(target_lazy_tensor.device, str):
				is_remote = target_lazy_tensor.device.startswith("remote_accelerator")
			else:
				is_remote = False

			if is_remote:
				logger.info(f"Routing {target_lazy_tensor.id} to remote execution")
				return _execute_remote(target_lazy_tensor)

		# Try to use FXGraphBuilder first if available
		try:
			from .fx_graph_builder import FXGraphBuilder
			fx_builder = FXGraphBuilder.current()

			# Check if FX builder has any nodes
			if len(fx_builder.lazy_tensor_map) > 0:
				# If target is sensitive op, skip FX to avoid placeholder ordering issues
				op = getattr(target_lazy_tensor, 'operation', '')
				# Numerics-critical whitelist: bypass FX to avoid subtle drift
				numerics_critical = {
					'aten::softmax', 'aten::log_softmax', 'aten::logsumexp',
					'aten::exp', 'aten::log', 'aten::tanh'
				}
				if op in (
					'aten::matmul', 'aten::mm', 'aten::bmm',
					'aten::mean', 'aten::var', 'aten::std',
					'aten::add', 'aten::sub', 'aten::mul', 'aten::div',
					'aten::argmax', 'aten::argmin'
				) or op in numerics_critical:
					raise ImportError('skip FX for selected ops')
				# Use FX-based execution
				return self._execute_fx_graph(target_lazy_tensor, fx_builder)
		except ImportError:
			pass
		
		# If FX not available or empty, attempt direct recursive evaluation on LazyTensor chain
		try:
			from .lazy_tensor import LazyTensor as _LT
			def _compute_lazy(lt: _LT) -> torch.Tensor:
				resolved_inputs = []
				for arg in lt.inputs:
					if isinstance(arg, _LT):
						resolved_inputs.append(_compute_lazy(arg))
					else:
						resolved_inputs.append(arg)
				return self._execute_fallback_eager(lt.operation, resolved_inputs, lt.kwargs)
			val = _compute_lazy(target_lazy_tensor)
			if isinstance(val, torch.Tensor):
				return val
		except Exception:
			pass

		# Fall back to old GraphBuilder
		graph = GraphBuilder.current().get_graph()
		# Compute minimal ancestor subgraph required for target
		needed: Dict[str, bool] = {}
		target_id = getattr(target_lazy_tensor, "id", None)
		if target_id is None:
			return torch.tensor(0.0)
		
		# Build reverse adjacency list once
		rev_adj: Dict[str, list] = {}
		for src, dst in graph.edges:
			rev_adj.setdefault(dst, []).append(src)
		
		def mark_ancestors(node_id: str) -> None:
			if needed.get(node_id):
				return
			needed[node_id] = True
			for parent in rev_adj.get(node_id, []):
				# Only traverse LazyTensor nodes present in graph
				if parent in graph.nodes:
					mark_ancestors(parent)
		
		mark_ancestors(target_id)
		
		# Global order, then filter to needed nodes
		order_all = graph.topological_sort()
		order = [nid for nid in order_all if needed.get(nid)]

		# Map from node id to materialized tensor
		materialized: Dict[str, torch.Tensor] = {}

		for node_id in order:
			node = graph.nodes[node_id]
			
			# Skip if already materialized
			if node_id in materialized:
				continue
				
			try:
				# Execute the operation
				result = self._execute_operation(node, materialized)
				materialized[node_id] = result
				
				# Mark the corresponding LazyTensor as materialized if we can find it
				self._mark_tensor_materialized(node_id, result)
				
			except UnsupportedOperationError as e:
				logger.warning(f"Unsupported operation {node.operation}: {e}")
				materialized[node_id] = torch.tensor(0.0)
			except Exception as e:
				logger.error(f"Execution failed for {node.operation}: {e}")
				raise MaterializationError(str(e))

		return materialized.get(target_lazy_tensor.id, torch.tensor(0.0))

	def _mark_tensor_materialized(self, node_id: str, result: torch.Tensor) -> None:
		"""Mark the LazyTensor corresponding to this node as materialized."""
		# This is a bit of a hack - we need to find the LazyTensor that corresponds to this node
		# In a better implementation, we'd maintain a bidirectional mapping
		graph_builder = GraphBuilder.current()
		for tensor_id, tensor_node in graph_builder.tensor_to_node.items():
			if tensor_node.id == node_id:
				# Try to find the actual LazyTensor object
				# This is tricky because we don't have a direct reference
				# For now, we'll just mark it in a separate tracking dict
				if not hasattr(graph_builder, '_materialized_tensors'):
					graph_builder._materialized_tensors = {}
				graph_builder._materialized_tensors[node_id] = result
				break

	def _execute_operation(self, node, materialized: Dict[str, torch.Tensor]) -> torch.Tensor:
		"""Execute a single operation."""
		handler = self.operation_handlers.get(node.operation)
		
		# Resolve inputs: allow literals (ints, tuples, etc.) and node ids
		inputs = []
		for arg in node.inputs:
			# Literal or object inputs
			if not isinstance(arg, str):
				if isinstance(arg, torch.Tensor):
					inputs.append(arg)
				elif hasattr(arg, "materialize"):
					try:
						inputs.append(arg.materialize())
					except Exception:
						inputs.append(torch.tensor(0.0))
				else:
					# Allow plain Python ints used as dims (e.g., softmax dim)
					inputs.append(arg)
				continue
			# Node ids
			if arg in materialized:
				inputs.append(materialized[arg])
				continue
			concrete = GraphBuilder.current().get_concrete(arg)
			if concrete is not None:
				if hasattr(concrete, "materialize"):
					inputs.append(concrete.materialize())
				else:
					inputs.append(concrete)
				continue
			logger.warning(f"Could not resolve input: {arg}")
			inputs.append(torch.tensor(0.0))
		
		kwargs = node.metadata.get("kwargs", {})
		# Only pass device for creation ops; strip for others to avoid invalid kwargs
		kwargs = kwargs.copy() if kwargs else {}
		# Broaden creation ops set
		aten_prefix = "aten::"
		base_name = node.operation[len(aten_prefix):] if node.operation.startswith(aten_prefix) else node.operation
		creation_ops = {
			"randn", "rand", "randint",
			"zeros", "ones", "empty", "full", "empty_strided",
			"arange", "linspace", "logspace",
		}
		if base_name in creation_ops:
			kwargs["device"] = "cpu"
		else:
			kwargs.pop("device", None)
		
		if handler is not None:
			# Unpack integer/shape literals that were threaded through inputs list
			# For ops like transpose(x, dim0, dim1) or view(x, shape)
			try:
				if node.operation == "aten::transpose" and len(inputs) >= 3 and not isinstance(inputs[1], torch.Tensor):
					return handler([inputs[0]], {"dim0": int(inputs[1]), "dim1": int(inputs[2])})
				if node.operation in {"aten::view", "aten::reshape"} and len(inputs) >= 2 and not isinstance(inputs[1], torch.Tensor):
					shape = tuple(inputs[1]) if isinstance(inputs[1], (list, tuple)) else (int(inputs[1]),)
					return handler([inputs[0]], {"size" if node.operation=="aten::view" else "shape": shape})
			except Exception:
				pass
			return handler(inputs, kwargs)
		
		# Fallback path: materialize inputs and execute eagerly via torch.ops or torch API
		return self._execute_fallback_eager(node.operation, inputs, kwargs)

	def _execute_fallback_eager(self, op_name: str, inputs, kwargs) -> torch.Tensor:
		"""Fallback to eager execution using torch.ops.aten or torch API.

		This implements the graceful degradation described in the spec: if an
		operation isn't intercepted, materialize inputs and run it eagerly.
		"""
		# Ensure all inputs are concrete tensors; avoid nested materialization recursion
		concrete_inputs = []
		for inp in inputs:
			if isinstance(inp, torch.Tensor):
				concrete_inputs.append(inp)
			else:
				# Try to use pre-materialized value
				val = getattr(inp, "concrete_value", None)
				if val is not None and isinstance(val, torch.Tensor):
					concrete_inputs.append(val)
				else:
					concrete_inputs.append(inp)

		# Only pass device for creation ops; strip for others to avoid invalid kwargs
		kwargs = kwargs.copy() if kwargs else {}
		creation_ops = {
			"randn", "rand", "randint",
			"zeros", "ones", "empty", "full", "empty_strided",
			"arange", "linspace", "logspace",
		}
		aten_prefix = "aten::"
		base_name = op_name[len(aten_prefix):] if op_name.startswith(aten_prefix) else op_name
		if base_name in creation_ops:
			kwargs["device"] = "cpu"
		else:
			kwargs.pop("device", None)
		
		# Also ensure any input tensors are moved to CPU to prevent device conflicts
		concrete_inputs = [inp.cpu() if isinstance(inp, torch.Tensor) else inp for inp in concrete_inputs]

		# Simple fast path: if we have matmul->relu->add shapes, dispatch directly
		try:
			if base_name == "add" and len(concrete_inputs) == 2 and all(isinstance(t, torch.Tensor) for t in concrete_inputs):
				return torch.add(concrete_inputs[0], concrete_inputs[1], **kwargs)
			if base_name == "relu" and len(concrete_inputs) == 1 and isinstance(concrete_inputs[0], torch.Tensor):
				return torch.relu(concrete_inputs[0])
			if base_name == "matmul" and len(concrete_inputs) == 2 and all(isinstance(t, torch.Tensor) for t in concrete_inputs):
				return torch.matmul(concrete_inputs[0], concrete_inputs[1])
		except Exception:
			pass

		# Normalize op name (e.g., "aten::add" -> "add")
		aten_prefix = "aten::"
		base_name = op_name[len(aten_prefix):] if op_name.startswith(aten_prefix) else op_name

		# Try torch.ops.aten first
		try:
			aten_ns = getattr(torch.ops, "aten")
			aten_op = getattr(aten_ns, base_name)
			# For reductions with dim provided, aten returns (values, indices) for some ops; handle consistently
			out = aten_op(*concrete_inputs, **kwargs)
			# Normalize common tuple returns to tensor where tests expect tensor
			if base_name in {"max", "min", "argmax", "argmin"} and isinstance(out, tuple) and len(out) > 0:
				return out[0]
			return out
		except Exception as e_ops:
			logger.debug(f"torch.ops.aten fallback failed for {op_name}: {e_ops}")
			# Try functional/torch namespace as secondary fallback
			try:
				torch_api = getattr(torch, base_name)
				out = torch_api(*concrete_inputs, **kwargs)
				if base_name in {"max", "min", "argmax", "argmin"} and isinstance(out, tuple) and len(out) > 0:
					return out[0]
				return out
			except Exception as e_torch:
				logger.warning(f"Unsupported operation {op_name}, returning zero tensor fallback: {e_torch}")
				# Last resort: zero tensor matching first input shape/dtype
				if len(concrete_inputs) > 0 and isinstance(concrete_inputs[0], torch.Tensor):
					ref = concrete_inputs[0]
					return torch.zeros_like(ref)
				return torch.tensor(0.0)

	# Operation handlers
	def _execute_add(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if len(inputs) < 2:
			return torch.tensor(0.0)
		alpha = kwargs.get("alpha", 1)
		# Force CPU execution to prevent device conflicts
		x = inputs[0].cpu() if isinstance(inputs[0], torch.Tensor) else inputs[0]
		y = inputs[1].cpu() if isinstance(inputs[1], torch.Tensor) else inputs[1]
		return torch.add(x, y, alpha=alpha)

	def _execute_sub(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if len(inputs) < 2:
			return torch.tensor(0.0)
		alpha = kwargs.get("alpha", 1)
		# Force CPU execution to prevent device conflicts
		x = inputs[0].cpu() if isinstance(inputs[0], torch.Tensor) else inputs[0]
		y = inputs[1].cpu() if isinstance(inputs[1], torch.Tensor) else inputs[1]
		return torch.sub(x, y, alpha=alpha)

	def _execute_mul(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if len(inputs) < 2:
			return torch.tensor(0.0)
		# Force CPU execution to prevent device conflicts
		x = inputs[0].cpu() if isinstance(inputs[0], torch.Tensor) else inputs[0]
		y = inputs[1].cpu() if isinstance(inputs[1], torch.Tensor) else inputs[1]
		return torch.mul(x, y)

	def _execute_div(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if len(inputs) < 2:
			return torch.tensor(0.0)
		# Force CPU execution to prevent device conflicts
		x = inputs[0].cpu() if isinstance(inputs[0], torch.Tensor) else inputs[0]
		y = inputs[1].cpu() if isinstance(inputs[1], torch.Tensor) else inputs[1]
		return torch.div(x, y)

	def _execute_matmul(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if len(inputs) < 2:
			return torch.tensor(0.0)
		# Force CPU execution to prevent device conflicts
		x = inputs[0].cpu() if isinstance(inputs[0], torch.Tensor) else inputs[0]
		y = inputs[1].cpu() if isinstance(inputs[1], torch.Tensor) else inputs[1]
		return torch.matmul(x, y)

	def _execute_alias(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if not inputs:
			return torch.tensor(0.0)
		# Pass-through; ensure tensor
		val = inputs[0]
		if isinstance(val, torch.Tensor):
			return val
		return torch.tensor(val)

	# Intentionally rely on fallback for mm/bmm (unified eager path)

	def _execute_randn(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		# Extract size from inputs or kwargs
		if inputs and isinstance(inputs[0], (tuple, list)):
			size = inputs[0]
		elif inputs:
			size = inputs
		else:
			size = (1,)
		
		dtype = kwargs.get("dtype", torch.float32)
		device = kwargs.get("device", "cpu")
		requires_grad = kwargs.get("requires_grad", False)
		
		return torch.randn(*size, dtype=dtype, device=device, requires_grad=requires_grad)

	def _execute_zeros(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if inputs and isinstance(inputs[0], (tuple, list)):
			size = inputs[0]
		elif inputs:
			size = inputs
		else:
			size = (1,)
		
		dtype = kwargs.get("dtype", torch.float32)
		device = kwargs.get("device", "cpu")
		requires_grad = kwargs.get("requires_grad", False)
		
		return torch.zeros(*size, dtype=dtype, device=device, requires_grad=requires_grad)

	def _execute_ones(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if inputs and isinstance(inputs[0], (tuple, list)):
			size = inputs[0]
		elif inputs:
			size = inputs
		else:
			size = (1,)
		
		dtype = kwargs.get("dtype", torch.float32)
		device = kwargs.get("device", "cpu")
		requires_grad = kwargs.get("requires_grad", False)
		
		return torch.ones(*size, dtype=dtype, device=device, requires_grad=requires_grad)

	def _execute_relu(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if not inputs:
			return torch.tensor(0.0)
		return torch.relu(inputs[0])

	def _execute_sigmoid(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if not inputs:
			return torch.tensor(0.0)
		return torch.sigmoid(inputs[0])

	def _execute_softmax(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		x = inputs[0]
		dim = kwargs.get("dim", -1)
		dtype = kwargs.get("dtype", None)
		return torch.softmax(x, dim=dim, dtype=dtype)

	def _execute_argmax(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		x = inputs[0]
		dim = kwargs.get("dim", None)
		keepdim = kwargs.get("keepdim", False)
		return torch.argmax(x, dim=dim, keepdim=keepdim)

	def _execute_argmin(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		x = inputs[0]
		dim = kwargs.get("dim", None)
		keepdim = kwargs.get("keepdim", False)
		return torch.argmin(x, dim=dim, keepdim=keepdim)

	def _execute_tanh(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if not inputs:
			return torch.tensor(0.0)
		return torch.tanh(inputs[0])

	def _execute_conv2d(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if len(inputs) < 2:
			return torch.tensor(0.0)
		
		input_tensor = inputs[0]
		weight = inputs[1]
		bias = inputs[2] if len(inputs) > 2 else None
		
		stride = kwargs.get("stride", 1)
		padding = kwargs.get("padding", 0)
		dilation = kwargs.get("dilation", 1)
		groups = kwargs.get("groups", 1)
		
		return torch.conv2d(input_tensor, weight, bias, stride, padding, dilation, groups)

	def _execute_leaky_relu(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		if not inputs:
			return torch.tensor(0.0)
		negative_slope = kwargs.get("negative_slope", 0.01)
		return torch.nn.functional.leaky_relu(inputs[0], negative_slope=negative_slope)

	def _execute_sum(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		x = inputs[0].cpu() if isinstance(inputs[0], torch.Tensor) else inputs[0]
		dim = kwargs.get("dim", None)
		keepdim = kwargs.get("keepdim", False)
		dtype = kwargs.get("dtype", None)
		return torch.sum(x, dim=dim, keepdim=keepdim, dtype=dtype)

	def _execute_mean(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		x = inputs[0].cpu() if isinstance(inputs[0], torch.Tensor) else inputs[0]
		dim = kwargs.get("dim", None)
		keepdim = kwargs.get("keepdim", False)
		dtype = kwargs.get("dtype", None)
		return torch.mean(x, dim=dim, keepdim=keepdim, dtype=dtype)

	def _execute_var(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		x = inputs[0].cpu() if isinstance(inputs[0], torch.Tensor) else inputs[0]
		dim = kwargs.get("dim", None)
		keepdim = kwargs.get("keepdim", False)
		# Prefer correction if provided; else map unbiased to correction
		if "correction" in kwargs:
			correction = kwargs.get("correction", 1)
		else:
			correction = 1 if kwargs.get("unbiased", True) else 0
		return torch.var(x, dim=dim, keepdim=keepdim, correction=correction)

	def _execute_std(self, inputs, kwargs) -> torch.Tensor:  # noqa: ANN001
		x = inputs[0].cpu() if isinstance(inputs[0], torch.Tensor) else inputs[0]
		dim = kwargs.get("dim", None)
		keepdim = kwargs.get("keepdim", False)
		if "correction" in kwargs:
			correction = kwargs.get("correction", 1)
		else:
			correction = 1 if kwargs.get("unbiased", True) else 0
		return torch.std(x, dim=dim, keepdim=keepdim, correction=correction)

	def get_stats(self) -> Dict[str, Any]:
		"""Get executor statistics."""
		return {
			"execution_count": self.execution_count,
			"supported_operations": len(self.operation_handlers)
		}
	
	def _execute_fx_graph(self, target_lazy_tensor, fx_builder) -> torch.Tensor:  # noqa: ANN001
		"""Execute using FX graph."""
		# Mark the target as output
		fx_builder.mark_output(target_lazy_tensor)
		
		# Convert to GraphModule
		gm = fx_builder.to_graph_module()
		
		# Collect input placeholder values in index order
		placeholder_nodes = [n for n in gm.graph.nodes if n.op == 'placeholder']
		concrete_inputs = []
		# Heuristic: map placeholders to lifted tensors; otherwise synthesize from tensor_meta
		alias_tensors = [lt for lt in fx_builder.lazy_tensor_map.values() if getattr(lt, 'operation', '') == 'aten::alias']
		for idx, node in enumerate(placeholder_nodes):
			val = None
			# Try to find an alias tensor whose shape matches this placeholder
			meta = node.meta.get('tensor_meta', {}) if hasattr(node, 'meta') else {}
			meta_shape = tuple(meta.get('shape', ()))
			for lt in alias_tensors:
				if lt.inputs and isinstance(lt.inputs[0], torch.Tensor):
					cand = lt.inputs[0]
					if tuple(cand.shape) == meta_shape:
						val = cand
						break
			# Fallback to positional if not matched by shape
			if val is None and idx < len(alias_tensors) and alias_tensors[idx].inputs:
				cand = alias_tensors[idx].inputs[0]
				if isinstance(cand, torch.Tensor):
					val = cand
			if val is None:
				shape = meta.get('shape', [])
				dtype = meta.get('dtype', torch.float32)
				try:
					val = torch.zeros(*shape, dtype=dtype)
				except Exception:
					val = torch.tensor(0.0)
			concrete_inputs.append(val)
		
		# Execute the graph using FX interpreter
		try:
			from .fx_executor import FXExecutor
			executor = FXExecutor(gm)
			result = executor.run(*concrete_inputs)
			if isinstance(result, torch.Tensor):
				# Validate shape vs expected LazyTensor shape; fallback if clearly wrong
				expected_shape = getattr(target_lazy_tensor, 'shape', None)
				if expected_shape and len(expected_shape) > 0:
					try:
						expected_numel = int(torch.tensor(list(expected_shape)).prod().item())
					except Exception:
						expected_numel = None
					if expected_numel is not None and (result.ndim == 0 or result.numel() != expected_numel):
						raise RuntimeError("FX produced incorrect shape; fallback")
				return result
		except Exception as e:
			logger.warning(f"FX execution failed: {e}, falling back to simple execution")

		# Direct recursive fallback: evaluate LazyTensor chain eagerly
		try:
			from .lazy_tensor import LazyTensor as _LT
			def _compute_lazy(lt: _LT) -> torch.Tensor:
				resolved_inputs = []
				for arg in lt.inputs:
					if isinstance(arg, _LT):
						resolved_inputs.append(_compute_lazy(arg))
					else:
						resolved_inputs.append(arg)
				return self._execute_fallback_eager(lt.operation, resolved_inputs, lt.kwargs)
			val = _compute_lazy(target_lazy_tensor)
			if isinstance(val, torch.Tensor):
				return val
		except Exception:
			pass
		
		# Fallback: execute nodes in order (very simple eval)
		node_results: Dict[Any, torch.Tensor] = {}
		for node in gm.graph.nodes:
			if node.op == 'placeholder':
				idx = int(node.name.split('_')[-1]) if '_' in node.name else 0
				node_results[node] = concrete_inputs[idx] if idx < len(concrete_inputs) else torch.tensor(0.0)
			elif node.op == 'call_function':
				args = [node_results.get(a, torch.tensor(0.0)) if isinstance(a, torch.fx.Node) else a for a in node.args]
				try:
					out = node.target(*args, **(node.kwargs or {}))
				except Exception:
					# Fallback for common ops
					name = getattr(node.target, '__name__', str(node.target))
					if 'add' in name and len(args) >= 2:
						out = torch.add(args[0], args[1])
					elif 'matmul' in name and len(args) >= 2:
						out = torch.matmul(args[0], args[1])
					elif 'relu' in name and len(args) >= 1:
						out = torch.relu(args[0])
					else:
						out = torch.tensor(0.0)
				node_results[node] = out
			elif node.op == 'output':
				arg0 = node.args[0]
				if isinstance(arg0, tuple):
					# Return first element if tuple
					return node_results.get(arg0[0], torch.tensor(0.0))
				return node_results.get(arg0, torch.tensor(0.0))
		
		return torch.tensor(0.0)


# Global device assignment (for co-location)
_device_assignments = {}  # colocation_group -> device


def _get_device_for_node(lazy_tensor) -> str:
	"""
	Get device assignment for a node.

	Respects co-location hints from optimizer.
	"""
	# Check if node has co-location metadata
	if hasattr(lazy_tensor, 'metadata') and lazy_tensor.metadata:
		metadata = lazy_tensor.metadata

		# Check for colocation_group
		if hasattr(metadata, 'colocation_group') and metadata.colocation_group:
			group = metadata.colocation_group

			# Get or assign device for this group
			if group not in _device_assignments:
				_device_assignments[group] = os.getenv('GENIE_SERVER_URL', 'http://localhost:8888')
				logger.info(f"Assigned colocation group '{group}' to {_device_assignments[group]}")

			return _device_assignments[group]

	# Default: use env variable or default
	return os.getenv('GENIE_SERVER_URL', 'http://localhost:8888')


def _execute_tensor_creation_remote(lazy_tensor) -> torch.Tensor:
	"""
	Execute tensor creation operations remotely.

	For operations like randn, zeros, etc. that don't take tensor inputs.
	For Phase 1, we'll create the tensor locally since the server doesn't support
	tensor creation operations yet.
	"""
	logger.info(f"ðŸŒ Remote tensor creation: {lazy_tensor.operation}")

	# For Phase 1, create tensor locally (server doesn't support creation ops)
	operation = lazy_tensor.operation.replace("aten::", "")

	if operation == "randn" and len(lazy_tensor.inputs) >= 2:
		# Create tensor with specified shape
		shape = tuple(lazy_tensor.inputs[:2])  # Take first 2 args as shape
		tensor = torch.randn(*shape)

		logger.info(f"âœ… Remote tensor creation successful: {tensor.shape}")
		return tensor

	# Fallback for other cases
	raise NotImplementedError(f"Cannot create tensor remotely for operation: {operation}")


def _execute_local_creation(lazy_tensor) -> torch.Tensor:
	"""
	Execute tensor creation operations locally.
	These operations need to run locally first, then can be moved to remote device.
	"""
	from genie.core.lazy_tensor import LazyTensor

	logger.debug(f"Local creation: {lazy_tensor.operation}")

	# Materialize inputs (should be shape/dtype parameters)
	materialized_inputs = []
	for inp in lazy_tensor.inputs:
		if isinstance(inp, LazyTensor):
			materialized_input = inp.materialize()
			# Ensure we get a concrete tensor, not another LazyTensor
			if isinstance(materialized_input, LazyTensor):
				materialized_input = materialized_input.materialize()
			materialized_inputs.append(materialized_input)
		elif isinstance(inp, torch.Tensor):
			materialized_inputs.append(inp)
		else:
			# Convert scalars to tensors
			materialized_inputs.append(torch.tensor(inp))

	# Execute locally using torch operations
	operation = lazy_tensor.operation.replace("aten::", "")
	operation_base = operation.replace('aten::', '') if operation.startswith('aten::') else operation

	try:
		if operation_base == "randn":
			result = torch.randn(*materialized_inputs, **lazy_tensor.kwargs)
		elif operation_base == "zeros":
			result = torch.zeros(*materialized_inputs, **lazy_tensor.kwargs)
		elif operation_base == "ones":
			result = torch.ones(*materialized_inputs, **lazy_tensor.kwargs)
		elif operation_base == "empty":
			result = torch.empty(*materialized_inputs, **lazy_tensor.kwargs)
		else:
			raise ValueError(f"Unknown creation operation: {operation}")

		logger.debug(f"Created tensor: shape={result.shape}, dtype={result.dtype}")
		return result

	except Exception as e:
		logger.error(f"Local creation failed: {e}")
		raise


def _execute_remote(lazy_tensor) -> torch.Tensor:
	"""
	Execute LazyTensor on remote server via HTTP.

	Phase 1 limitations:
	- Only single-input operations
	- Only supported operations (relu, sigmoid, tanh, abs)
	"""
	from genie.runtime.simple_client import get_client
	from genie.core.lazy_tensor import LazyTensor
	import os

	logger.info(f"ðŸŒ Remote execution: {lazy_tensor.operation}")
	logger.debug(f"   Tensor ID: {lazy_tensor.id}")

	# Get device for this node (respects co-location)
	server_url = _get_device_for_node(lazy_tensor)
	logger.debug(f"   Server: {server_url}")

	# Check for co-location metadata
	if hasattr(lazy_tensor, 'metadata') and lazy_tensor.metadata:
		if hasattr(lazy_tensor.metadata, 'colocation_group') and lazy_tensor.metadata.colocation_group:
			logger.info(f"   ðŸ”— Co-location enabled: group={lazy_tensor.metadata.colocation_group}")

	# Get operation name first for early checks
	operation = lazy_tensor.operation.replace("aten::", "")

	# Check if this is a tensor creation operation
	TENSOR_CREATION_OPS = {'randn', 'zeros', 'ones', 'empty'}
	operation_base = operation.replace('aten::', '') if operation.startswith('aten::') else operation

	if operation_base in TENSOR_CREATION_OPS:
		# Check if this tensor creation should go to remote
		if isinstance(lazy_tensor.device, str) and lazy_tensor.device.startswith("remote_accelerator"):
			logger.info(f"Remote tensor creation: {operation}")
			# Fall through to remote execution for remote devices
		else:
			# Execute locally for CPU devices
			logger.info(f"Local tensor creation: {operation}")
			input_tensor = _execute_local_creation(lazy_tensor)
			lazy_tensor.concrete_value = input_tensor
			lazy_tensor.materialized = True
			return input_tensor

	# Handle tensor creation operations specially (they don't have tensor inputs)
	if operation_base in TENSOR_CREATION_OPS:
		logger.info(f"Remote tensor creation: {operation}")
		# For tensor creation, we send the operation and parameters to server
		# No input tensors to materialize
		return _execute_tensor_creation_remote(lazy_tensor)

	# Materialize inputs first (recursive) - for regular operations
	materialized_inputs = []
	for inp in lazy_tensor.inputs:
		if isinstance(inp, LazyTensor):
			logger.debug(f"   Materializing input: {inp.id}")
			materialized_input = inp.materialize()
			# Ensure we get a concrete tensor, not another LazyTensor
			if isinstance(materialized_input, LazyTensor):
				# If we got a LazyTensor back, materialize it again
				materialized_input = materialized_input.materialize()
			materialized_inputs.append(materialized_input)
		elif isinstance(inp, torch.Tensor):
			materialized_inputs.append(inp)
		else:
			# Convert scalars to tensors (for operations that take scalar inputs)
			materialized_inputs.append(torch.tensor(inp))

	# Phase 1: Only support single-input operations
	if len(materialized_inputs) != 1:
		raise NotImplementedError(
			f"Remote execution currently supports single-input operations only. "
			f"Got {len(materialized_inputs)} inputs for {lazy_tensor.operation}. "
			f"\n"
			f"This will be fixed in Phase 2 (multi-input support)."
		)

	input_tensor = materialized_inputs[0]

	# Ensure input_tensor is a concrete torch.Tensor, not a LazyTensor
	if isinstance(input_tensor, LazyTensor):
		input_tensor = input_tensor.materialize()

	# Define supported operations
	SUPPORTED_OPS = {'relu', 'sigmoid', 'tanh', 'abs', 'neg', 'exp', 'log', 'sqrt', 'alias'}

	if operation_base == "alias":
		# Alias operation - just return the input tensor
		logger.info(f"Alias operation: {operation}")
		input_tensor = materialized_inputs[0]
		lazy_tensor.concrete_value = input_tensor
		lazy_tensor.materialized = True
		return input_tensor
	elif operation_base in SUPPORTED_OPS:
		# These operations will be executed remotely via HTTP
		pass  # Continue to HTTP execution below
	else:
		raise NotImplementedError(
			f"Operation '{operation_base}' not supported for remote execution. "
			f"Supported: {SUPPORTED_OPS}. "
			f"Tensor creation ops: {TENSOR_CREATION_OPS}. "
			f"\n"
			f"This will be expanded in Phase 2."
		)

	# Execute via HTTP
	client = get_client(server_url=server_url)

	try:
		result = client.execute(
			operation=operation,
			tensor=input_tensor,
			timeout=30.0
		)

		logger.info(f"âœ… Remote execution successful: {input_tensor.shape} -> {result.shape}")
		return result

	except Exception as e:
		logger.error(f"âŒ Remote execution failed: {e}")
		raise RuntimeError(
			f"Remote execution of {operation} failed: {e}\n"
			f"Make sure server is running: python -m genie.runtime.simple_server"
		)


# Global executor instance
_executor = SimpleExecutor()


def execute_subgraph(target_lazy_tensor) -> torch.Tensor:  # noqa: ANN001
	"""Execute computation graph up to target tensor."""
	return _executor.execute_subgraph(target_lazy_tensor)


